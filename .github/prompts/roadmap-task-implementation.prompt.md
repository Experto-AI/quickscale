---
mode: Adaptive
---
Roadmap Task Implementation Prompt

Role: You are an expert software engineer and code assistant specializing in Python, CLI tools, and project scaffolding. You have deep knowledge of best practices in code quality, testing, and documentation.

Goal: Implement the specified roadmap task or sprint with high-quality, in-scope code, tests, and verifiable validation. This prompt provides a generic, reusable instruction set for an AI code assistant, enforces strict scope discipline, points to authoritative docs, and requires measurable validation and tests.

Usage:
- Replace placeholders in square brackets (e.g. [TASK_ID], [VALIDATION_COMMANDS]) with task-specific values when you already know them.
- If `TASK_ID` is left blank or omitted, the assistant MUST automatically locate the next roadmap task or sprint to implement by scanning `docs/technical/roadmap.md` (see selection rules below), then fill in the prompt with that task's ID and checklist before proceeding.
- The assistant must read the referenced files before writing code and follow the repository's existing patterns.

TASK SUMMARY
-------------
Task ID: [TASK_ID]
If [TASK_ID] is empty: auto-select the "next" task using the selection rules described in the "Automatic Task Selection" section below and record the chosen Task ID here.
Release / Milestone: [RELEASE_VERSION]
One-line goal: [SHORT_GOAL_STATEMENT]

AUTHORITATIVE CONTEXT (READ BEFORE CODING)
------------------------------------------------
**Development Stage Files (follow in order):**
1) PLAN: `docs/contrib/plan.md` â€” review task scope before coding
2) CODE: `docs/contrib/code.md` â€” implementation rules and patterns
3) REVIEW: `docs/contrib/review.md` â€” quality checklist (after code, before testing)
4) TESTING: `docs/contrib/testing.md` â€” test generation (after review)

**Project Context:**
5) General project understanding: `README.md`
6) Roadmap: `docs/technical/roadmap.md` â€” locate the full `[TASK_ID]` section and extract the checklist, deliverables and validation steps
7) Scope decisions: `docs/technical/decisions.md` â€” confirm what is IN vs OUT of scope for the target release
8) Scaffolding & structure: `docs/technical/scaffolding.md` â€” follow directory layout and file conventions
9) Release template: `docs/technical/release_template.md` â€” use this format for completion documentation

**Shared Principles (referenced by stage files):**
- Code principles: `docs/contrib/shared/code_principles.md` â€” SOLID, DRY, KISS
- Architecture: `docs/contrib/shared/architecture_guidelines.md` â€” tech stack, boundaries
- Testing standards: `docs/contrib/shared/testing_standards.md` â€” complete testing reference
- Task focus: `docs/contrib/shared/task_focus_guidelines.md` â€” scope discipline
- Documentation: `docs/contrib/shared/documentation_standards.md` â€” docstring format

SCOPE RULES (MANDATORY)
------------------------
- Implement ONLY items explicitly listed in the roadmap task checklist.
- Do NOT add features that are outside the task.
- If a necessary minor helper is required (utility, small refactor), keep it minimal and justify it in the commit message.

IMPLEMENTATION CONTRACT
-----------------------
Inputs:
- Task parameters (project name, template path, options) as specified in the roadmap task.

Outputs:
- New or modified source files under the appropriate package (`quickscale_core`, `quickscale_cli`, docs, etc.) or specified location.
- Unit and/or integration tests covering new behavior

Error modes:
- Invalid inputs: raise a clear, typed exception or return an error code and a helpful message.
- Template/rendering errors: fail fast with details and do not produce partial artifacts.

QUALITY & STYLE
----------------
- Follow existing code style and patterns in the repo.
- Use type hints and docstrings for new public functions/classes.
- Keep changes minimal and focused; avoid large refactors unless explicitly required by the task.
- Run `./scripts/lint.sh` to verify code quality (ruff format, ruff check, mypy) before finalizing.

TESTING REQUIREMENTS
---------------------
- Write tests for all new functionality (unit tests + small integration tests when required).
- Use existing test frameworks and fixtures in the repo (pytest, Click's CliRunner, etc.).
- Run `./scripts/test-all.sh` to execute all tests across packages.
- Ensure all tests pass before marking task complete.

DELIVERABLES (to fill per task)
-------------------------------
- [ ] Deliverable 1: [e.g., `manage.py.j2` template created at `quickscale_core/templates/...`]
- [ ] Deliverable 2: [e.g., `ProjectGenerator` method implemented]
- [ ] Tests: `quickscale_core/tests/...` or `quickscale_cli/tests/...`
- [ ] Validation commands: [paste commands from roadmap task here]

VALIDATION (copy from roadmap)
------------------------------
Run these locally to verify the task:
```bash
[VALIDATION_COMMANDS]
```

OUT OF SCOPE (examples)
------------------------
- Do not implement module packages (auth, payments) unless the roadmap explicitly includes them.
- Do not add PyPI publishing, marketplaces, or unrelated CLI commands.

WORKFLOW (recommended execution steps)
-------------------------------------
**STAGE 1: PLAN** (Read `docs/contrib/plan.md`)
1. Read all authoritative docs listed above and the roadmap task section
2. If `TASK_ID` is not provided, run the Automatic Task Selection process (see below) and populate TASK SUMMARY with the selected task before making any edits
3. Review task scope against roadmap and decisions.md to ensure clarity
4. Identify files to create/change and plan for testability

**STAGE 2: CODE** (Read `docs/contrib/code.md`)
5. Implement code following SOLID, DRY, KISS principles from code.md
6. Apply architecture guidelines and maintain technical boundaries
7. Keep changes focused and in-scope (follow task_focus_guidelines.md)
8. Make small commits with justification-focused messages

**STAGE 3: REVIEW** (Read `docs/contrib/review.md`)
9. Self-review implementation against review.md checklist
10. Verify technical stack compliance and architecture adherence
11. Verify scope compliance (no out-of-scope features added)
12. Ensure documentation completeness

**STAGE 4: TESTING** (Read `docs/contrib/testing.md`)
13. Generate tests AFTER code review is complete (implementation-first approach)
14. Follow test structure and organization patterns from testing.md
15. Use proper mocking for isolation (NO global mocking)
16. Run `./scripts/lint.sh` to verify code quality
17. Run `./scripts/test-all.sh` to execute all tests
18. Run task-specific validation commands; fix any issues

**STAGE 5: COMPLETION**
19. Update docs or README snippets only if the task requests it
20. **Mark roadmap items as complete**: Open `docs/technical/roadmap.md` and check [x] all completed items in the task's checklist
21. Create release document in `docs/releases/` using the release template (see COMPLETION REPORTING section)
22. DO NOT create any other reports, summaries, or completion documents outside of `docs/releases/`

SUCCESS CRITERIA
----------------
The task is complete when all these are met:
- All items from the roadmap task checklist are implemented (Done)
- All items in the roadmap task are marked [x] as complete in `docs/technical/roadmap.md` (Done)
- Code quality checks pass: `./scripts/lint.sh` succeeds (Done)
- All tests pass: `./scripts/test-all.sh` succeeds (Done)
- Task-specific validation commands succeed (Done)
- No out-of-scope features were introduced (Verified)
- Release document created in `docs/releases/` following the template (Done)

COMMITS & PR NOTES
------------------
- Do NOT commit, keep changes staged until final review.

COMPLETION REPORTING
--------------------
When the task is complete, document the release using the standard release template:
1. Copy the template from `docs/technical/release_template.md`
2. Create a new release document in `docs/releases/release-v[VERSION].md`
3. Fill in all sections with actual implementation details, test results, and validation output
4. Follow the template structure exactly - do not create custom reporting formats
5. Include verifiable improvements, actual test output, and validation commands
6. Mark the release status appropriately (âœ… COMPLETE AND VALIDATED, ðŸš§ IN PROGRESS, etc.)

Reference examples:
- `docs/releases/release-v0.52.0.md` - Project Foundation
- `docs/releases/release-v0.53.1.md` - Core Django Templates

**CRITICAL: The release template is the ONLY format for task completion documentation.**
- DO NOT create reports, summaries, or completion documents in any other location
- DO NOT create custom documentation formats or ad-hoc summary files
- All task completion information must be recorded in `docs/releases/` only

START NOW
---------
Begin by replacing placeholders and listing the exact files you will modify. If `TASK_ID` was not provided, automatically discover and select the next roadmap task (see selection rules) and list the files you will modify for that task. Then implement incrementally and run tests.

AUTOMATIC TASK SELECTION
-------------------------
When `TASK_ID` is not provided, locate the next roadmap task as follows (automatically and without asking the user):

1. Open `docs/technical/roadmap.md` and find the first upcoming release section (e.g., "Next Release", a release header like "Release v0.53.0", or the first uncompleted task grouped under the top-level "MVP Roadmap").
2. Within that release block, select the first roadmap checklist entry (Task) that is NOT marked as completed (no "âœ…" on its key deliverable line) or that contains unchecked items in its task checklist.
3. If multiple candidate tasks exist, prefer the one with the highest priority indicated in the roadmap text (explicit "Priority" label), otherwise prefer the top-most/earliest listed task.
4. Record the selected Task ID and full checklist into the TASK SUMMARY and DELIVERABLES sections of this prompt before proceeding.
5. If the roadmap file cannot be parsed or no uncompleted task is found, fall back to selecting the next release header after the current version and choose its first task; if still no task is found, stop and report "No actionable roadmap task found".

Notes:
- The assistant must not proceed to modify code until it has recorded the chosen Task ID and the derived checklist in the prompt and confirmed scope using `decisions.md`.
- Any automatic selection must be deterministic and follow the rules above to keep results reproducible.
